{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a49a32b-a36a-4da3-9102-a4a41ae7bc41",
      "metadata": {
        "id": "3a49a32b-a36a-4da3-9102-a4a41ae7bc41"
      },
      "source": [
        "# Large Dataset Loading and Preparation Scripts\n",
        "\n",
        "Just for demonstration purposes, do not run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "447939fa-a85b-4158-bdec-2a3eb95df47a",
      "metadata": {
        "id": "447939fa-a85b-4158-bdec-2a3eb95df47a"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap\n",
        "import os\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import cenpy\n",
        "import pygris\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e04b893-4cdc-41fe-a804-b648e7427440",
      "metadata": {
        "id": "3e04b893-4cdc-41fe-a804-b648e7427440"
      },
      "source": [
        "## 1. Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12580b93-f4e2-446b-a57f-3b2e37d51ce8",
      "metadata": {
        "id": "12580b93-f4e2-446b-a57f-3b2e37d51ce8"
      },
      "outputs": [],
      "source": [
        "ee.Authenticate()\n",
        "ee.Initialize(project=\"gee-emilyzhou0112\") # replace with your own project name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58e8cdc5-3d7e-4d17-8b5b-7e3c99aae8d3",
      "metadata": {
        "id": "58e8cdc5-3d7e-4d17-8b5b-7e3c99aae8d3"
      },
      "outputs": [],
      "source": [
        "pa_tracts = gpd.read_file('PATH')\n",
        "pa_bound = pa_tracts.dissolve() # dissolve geometry to get the boundary\n",
        "pa_geom= ee.Geometry.Polygon(list(pa_bound['geometry'].iloc[0].exterior.coords)) # convert the geometry into a format suitable for gee\n",
        "aoi = ee.FeatureCollection(pa_geom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c13ebeb-61ef-45f7-8e90-d52ed830cffa",
      "metadata": {
        "id": "5c13ebeb-61ef-45f7-8e90-d52ed830cffa"
      },
      "outputs": [],
      "source": [
        "tolerance = 0.01\n",
        "pa_tracts['geometry'] = pa_tracts['geometry'].simplify(tolerance, preserve_topology=True)\n",
        "pa_tracts_ee = geemap.geopandas_to_ee(pa_tracts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cc43950-d911-446b-b459-ea9e7c41a942",
      "metadata": {
        "id": "3cc43950-d911-446b-b459-ea9e7c41a942"
      },
      "source": [
        "## 2. Landsat Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba288ab-fc5d-4197-9241-87cb2a9e04aa",
      "metadata": {
        "id": "bba288ab-fc5d-4197-9241-87cb2a9e04aa"
      },
      "outputs": [],
      "source": [
        "## Define Time Period\n",
        "startSpring = datetime(2022, 3, 1) # spring\n",
        "endSpring = datetime(2022, 5, 31)\n",
        "startSummer = datetime(2022, 6, 1) # summer\n",
        "endSummer = datetime(2022, 8, 31)\n",
        "startFall = datetime(2022, 9, 1) # fall\n",
        "endFall = datetime(2022, 11, 30)\n",
        "startWinter = datetime(2022, 12, 1) # winter\n",
        "endWinter = datetime(2023, 2, 28)\n",
        "\n",
        "# Format dates into strings that Earth Engine expects (\"YYYY-MM-DD\")\n",
        "startSpring= startSpring.strftime('%Y-%m-%d')\n",
        "endSpring = endSpring.strftime('%Y-%m-%d')\n",
        "startSummer = startSummer.strftime('%Y-%m-%d')\n",
        "endSummer = endSummer.strftime('%Y-%m-%d')\n",
        "startFall = startFall.strftime('%Y-%m-%d')\n",
        "endFall = endFall.strftime('%Y-%m-%d')\n",
        "startWinter = startWinter.strftime('%Y-%m-%d')\n",
        "endWinter = endWinter.strftime('%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f5f1492-2682-4b65-8755-cedfa0176ae0",
      "metadata": {
        "id": "2f5f1492-2682-4b65-8755-cedfa0176ae0"
      },
      "outputs": [],
      "source": [
        "## Helper Function - Scale Bands\n",
        "def apply_scale_factors(image):\n",
        "    # Scale and offset values for optical bands\n",
        "    optical_bands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
        "\n",
        "    # Scale and offset values for thermal bands\n",
        "    thermal_bands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
        "\n",
        "    # Add scaled bands to the original image\n",
        "    return image.addBands(optical_bands, None, True) \\\n",
        "                .addBands(thermal_bands, None, True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94df196f-ee62-4fae-9748-7f29c0a87da2",
      "metadata": {
        "id": "94df196f-ee62-4fae-9748-7f29c0a87da2"
      },
      "outputs": [],
      "source": [
        "## Helper Function - Mask Clouds\n",
        "def cloud_mask(image):\n",
        "    # Define cloud shadow and cloud bitmask (Bits 3 and 5)\n",
        "    cloud_shadow_bit_mask = 1 << 3\n",
        "    cloud_bit_mask = 1 << 5\n",
        "\n",
        "    # Select the Quality Assessment (QA) band for pixel quality information\n",
        "    qa = image.select('QA_PIXEL')\n",
        "\n",
        "    # Create a binary mask to identify clear conditions (both cloud and cloud shadow bits set to 0)\n",
        "    mask = qa.bitwiseAnd(cloud_shadow_bit_mask).eq(0) \\\n",
        "                .And(qa.bitwiseAnd(cloud_bit_mask).eq(0))\n",
        "\n",
        "    # Update the original image, masking out cloud and cloud shadow-affected pixels\n",
        "    return image.updateMask(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7dd40b-3891-4ee1-a192-e44f120ddd3e",
      "metadata": {
        "id": "8e7dd40b-3891-4ee1-a192-e44f120ddd3e"
      },
      "outputs": [],
      "source": [
        "def calculate_seasonal_indices(image_collection, aoi, season_name):\n",
        "    \"\"\"\n",
        "    Calculate NDVI, SAVI, EVI, Fraction of Vegetation (FV),\n",
        "    Emissivity (EM), and Land Surface Temperature (LST) for a season.\n",
        "\n",
        "    Parameters:\n",
        "    - image_collection: ee.ImageCollection, the collection of images for the season.\n",
        "    - aoi: ee.Geometry, the area of interest.\n",
        "    - season_name: str, name of the season (for debugging/logging purposes).\n",
        "\n",
        "    Returns:\n",
        "    - ee.Image, containing the calculated indices and LST.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate NDVI\n",
        "    ndvi = image_collection.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')\n",
        "\n",
        "    # Calculate SAVI\n",
        "    savi = image_collection.expression(\n",
        "        '1.5 * (NIR - RED) / (NIR + RED + 0.5)', {\n",
        "            'NIR': image_collection.select('SR_B5'),\n",
        "            'RED': image_collection.select('SR_B4')\n",
        "        }\n",
        "    ).rename('SAVI')\n",
        "\n",
        "    # Calculate EVI\n",
        "    evi = image_collection.expression(\n",
        "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
        "            'NIR': image_collection.select('SR_B5'),\n",
        "            'RED': image_collection.select('SR_B4'),\n",
        "            'BLUE': image_collection.select('SR_B2')\n",
        "        }\n",
        "    ).rename('EVI')\n",
        "\n",
        "    # NDVI min and max for Fraction of Vegetation (FV) calculation\n",
        "    ndvi_min = ndvi.reduceRegion(\n",
        "        reducer=ee.Reducer.min(),\n",
        "        geometry=aoi,\n",
        "        scale=30,\n",
        "        maxPixels=1e9\n",
        "    ).get('NDVI')\n",
        "\n",
        "    ndvi_max = ndvi.reduceRegion(\n",
        "        reducer=ee.Reducer.max(),\n",
        "        geometry=aoi,\n",
        "        scale=30,\n",
        "        maxPixels=1e9\n",
        "    ).get('NDVI')\n",
        "\n",
        "    # Convert NDVI_min and NDVI_max to ee.Number\n",
        "    ndvi_min = ee.Number(ndvi_min)\n",
        "    ndvi_max = ee.Number(ndvi_max)\n",
        "\n",
        "    # Fraction of Vegetation (FV)\n",
        "    fv = ndvi.subtract(ndvi_min).divide(ndvi_max.subtract(ndvi_min)).pow(2).rename('FV')\n",
        "\n",
        "    # Emissivity (EM)\n",
        "    em = fv.multiply(0.004).add(0.986).rename('EM')\n",
        "\n",
        "    # Thermal band (Band 10)\n",
        "    thermal = image_collection.select('ST_B10').rename('thermal')\n",
        "\n",
        "    # Land Surface Temperature (LST)\n",
        "    lst = thermal.expression(\n",
        "        '(TB / (1 + (0.00115 * (TB / 1.438)) * log(em))) - 273.15',\n",
        "        {\n",
        "            'TB': thermal.select('thermal'),  # Thermal band temperature in Kelvin\n",
        "            'em': em  # Emissivity\n",
        "        }\n",
        "    ).rename('LST')\n",
        "\n",
        "    seasonal_image = ndvi.addBands([savi, evi, fv, em, lst])\n",
        "    return seasonal_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc32d8a0-ec9e-4803-b90c-6ac6534b8631",
      "metadata": {
        "id": "dc32d8a0-ec9e-4803-b90c-6ac6534b8631"
      },
      "outputs": [],
      "source": [
        "seasons = {\n",
        "    'spring': (startSpring, endSpring),\n",
        "    'summer': (startSummer, endSummer),\n",
        "    'fall': (startFall, endFall),\n",
        "    'winter': (startWinter, endWinter)\n",
        "}\n",
        "\n",
        "seasonal_results = {}\n",
        "for season, (start_date, end_date) in seasons.items():\n",
        "    image_collection = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\") \\\n",
        "        .filterBounds(aoi) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .map(apply_scale_factors) \\\n",
        "        .map(cloud_mask) \\\n",
        "        .median() \\\n",
        "        .clip(aoi)\n",
        "\n",
        "    seasonal_results[season] = calculate_seasonal_indices(image_collection, aoi, season)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2635bb7b-7196-4866-94ee-e75c519dcd45",
      "metadata": {
        "id": "2635bb7b-7196-4866-94ee-e75c519dcd45"
      },
      "outputs": [],
      "source": [
        "# Function to export zonal stats to Google Drive\n",
        "def export_zonal_stats(image, reducer, file_name, folder_name=\"FILE NAME\"):\n",
        "    \"\"\"\n",
        "    Exports zonal statistics of an image band to Google Drive as a CSV.\n",
        "\n",
        "    Parameters:\n",
        "    - image: ee.Image, the image containing the band to export.\n",
        "    - reducer: ee.Reducer, the reducer to aggregate data (e.g., mean, median).\n",
        "    - file_name: str, name of the file (e.g., 'ndvi_spring.csv').\n",
        "    - folder_name: str, Google Drive folder to save the file in.\n",
        "    \"\"\"\n",
        "    zonal_stats = image.reduceRegions(\n",
        "        collection=pa_tracts_ee,\n",
        "        reducer = ee.Reducer.mean()\n",
        "        scale=30  # Resolution of the analysis\n",
        "    )\n",
        "\n",
        "    task = ee.batch.Export.table.toDrive(\n",
        "        collection=zonal_stats,\n",
        "        fileFormat='CSV',\n",
        "        fileNamePrefix=file_name.replace('.csv', ''),\n",
        "        folder=folder_name\n",
        "    )\n",
        "    task.start()\n",
        "    print(f\"Export started for {file_name}. Check Google Drive for the results.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c3cd87b-3a49-4e39-9f12-65ad228046f0",
      "metadata": {
        "id": "6c3cd87b-3a49-4e39-9f12-65ad228046f0"
      },
      "outputs": [],
      "source": [
        "# Seasonal results containing all seasonal images with bands\n",
        "seasonal_results = {\n",
        "    \"spring\": seasonal_results['spring'],\n",
        "    \"summer\": seasonal_results['summer'],\n",
        "    \"fall\": seasonal_results['fall'],\n",
        "    \"winter\": seasonal_results['winter']\n",
        "}\n",
        "\n",
        "# List of bands to process\n",
        "bands = ['NDVI', 'EVI', 'SAVI', 'LST']\n",
        "\n",
        "# Export each band for every season\n",
        "for season, image in seasonal_results.items():\n",
        "    for band in bands:\n",
        "        band_image = image.select(band)  # Extract specific band\n",
        "        file_name = f\"{band.lower()}_{season}.csv\"  # File name e.g., ndvi_spring.csv\n",
        "        export_zonal_stats(image=band_image, reducer=reducer, file_name=file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da4a06a-ec45-4639-963b-6e9bd246371c",
      "metadata": {
        "id": "8da4a06a-ec45-4639-963b-6e9bd246371c"
      },
      "source": [
        "## 3. Land Cover Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3239a4a9-4a89-499e-aa57-08e09e8fd2af",
      "metadata": {
        "id": "3239a4a9-4a89-499e-aa57-08e09e8fd2af"
      },
      "outputs": [],
      "source": [
        "dataset = ee.ImageCollection('USGS/NLCD_RELEASES/2021_REL/NLCD')\n",
        "nlcd2021 = dataset.filter(ee.Filter.eq('system:index', '2021')).first()\n",
        "landcover = nlcd2021.select('landcover')\n",
        "pa_landcover = landcover.clip(aoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9492ef72-4c03-4800-a22b-b1f1f0c02784",
      "metadata": {
        "id": "9492ef72-4c03-4800-a22b-b1f1f0c02784"
      },
      "outputs": [],
      "source": [
        "high_density = pa_landcover.eq(23).Or(pa_landcover.eq(24))\n",
        "low_density = pa_landcover.eq(21).Or(pa_landcover.eq(22))\n",
        "forest = pa_landcover.eq(41).Or(pa_landcover.eq(42)).Or(pa_landcover.eq(43))\n",
        "grasses = pa_landcover.eq(52).Or(pa_landcover.eq(71)).Or(pa_landcover.eq(81)).Or(pa_landcover.eq(82))\n",
        "wetlands = pa_landcover.eq(90).Or(pa_landcover.eq(95))\n",
        "open_water = pa_landcover.eq(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e228535f-5976-4906-bb68-79b7df7cfe8a",
      "metadata": {
        "id": "e228535f-5976-4906-bb68-79b7df7cfe8a"
      },
      "outputs": [],
      "source": [
        "def neighboring_landcover_metrics(landcover_mask, file_name):\n",
        "    \"\"\"\n",
        "    Function to calculate total and neighboring land cover metrics and export them as a CSV.\n",
        "\n",
        "    Args:\n",
        "        landcover_mask (ee.Image): Binary mask of the landcover categories to analyze.\n",
        "        pa_tracts_ee (ee.FeatureCollection): The census tracts FeatureCollection.\n",
        "        description (str): Description for the export task.\n",
        "        file_name (str): File name prefix for the exported CSV.\n",
        "    \"\"\"\n",
        "    # Define the kernel for neighboring pixels\n",
        "    kernel = ee.Kernel.square(radius=1, units='pixels')  # 3x3 neighborhood\n",
        "    neighbors = landcover_mask.convolve(kernel).gte(1)  # At least one neighbor\n",
        "\n",
        "    # Calculate total landcover pixels\n",
        "    total_landcover = landcover_mask.reduceRegions(\n",
        "        collection=pa_tracts_ee,\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        scale=30\n",
        "    ).select(['sum'], ['total_landcover'])\n",
        "\n",
        "    # Calculate neighboring landcover pixels\n",
        "    neighbor_landcover = neighbors.reduceRegions(\n",
        "        collection=pa_tracts_ee,\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        scale=30\n",
        "    ).select(['sum'], ['neighbor_landcover'])\n",
        "\n",
        "    # Merge FeatureCollections and retain geoid\n",
        "    merged_fc = total_landcover.map(lambda feature:\n",
        "        feature.set(\n",
        "            'neighbor_landcover',\n",
        "            neighbor_landcover.filter(ee.Filter.eq('system:index', feature.get('system:index')))\n",
        "                              .first()\n",
        "                              .get('neighbor_landcover')\n",
        "        ).set(\n",
        "            'geoid', pa_tracts_ee.filter(ee.Filter.eq('system:index', feature.get('system:index')))\n",
        "                                 .first()\n",
        "                                 .get('GEOID')\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Export the merged FeatureCollection\n",
        "    export_task = ee.batch.Export.table.toDrive(\n",
        "        collection=merged_fc.select(['geoid', 'total_landcover', 'neighbor_landcover']),\n",
        "        folder='FOLDER NAME',\n",
        "        fileNamePrefix=file_name,\n",
        "        fileFormat='CSV'\n",
        "    )\n",
        "    export_task.start()\n",
        "    print(f\"Export task started: {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebbe1c4-5e50-45b6-9335-bffd2c746654",
      "metadata": {
        "id": "0ebbe1c4-5e50-45b6-9335-bffd2c746654"
      },
      "outputs": [],
      "source": [
        "neighboring_landcover_metrics(\n",
        "    landcover_mask=forest,\n",
        "    file_name='forest_landcover_metrics'\n",
        ")\n",
        "\n",
        "neighboring_landcover_metrics(\n",
        "    landcover_mask=high_density,\n",
        "    file_name='high_density_landcover_metrics'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "218d8b22-837b-4fd6-aae6-692c083f6eed",
      "metadata": {
        "id": "218d8b22-837b-4fd6-aae6-692c083f6eed"
      },
      "outputs": [],
      "source": [
        "def summarize_landcover_pixels(landcover_mask, file_name):\n",
        "    \"\"\"\n",
        "    Function to summarize total landcover pixels for each tract and export as a CSV.\n",
        "\n",
        "    Args:\n",
        "        landcover_mask (ee.Image): Binary mask of the landcover categories to analyze.\n",
        "        pa_tracts_ee (ee.FeatureCollection): The census tracts FeatureCollection.\n",
        "        description (str): Description for the export task.\n",
        "        file_name (str): File name prefix for the exported CSV.\n",
        "    \"\"\"\n",
        "    # Calculate total landcover pixels\n",
        "    total_landcover = landcover_mask.reduceRegions(\n",
        "        collection=pa_tracts_ee,\n",
        "        reducer=ee.Reducer.sum(),\n",
        "        scale=30\n",
        "    ).map(lambda feature: feature.set(\n",
        "        'geoid', feature.get('GEOID')\n",
        "    ))\n",
        "\n",
        "    # Export the results to Drive\n",
        "    export_task = ee.batch.Export.table.toDrive(\n",
        "        collection=total_landcover.select(['geoid', 'sum']),\n",
        "        folder='FOLDER NAME',\n",
        "        fileNamePrefix=file_name,\n",
        "        fileFormat='CSV'\n",
        "    )\n",
        "    export_task.start()\n",
        "    print(f\"Export task started: {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a799a27d-2f06-4794-846f-343377d62321",
      "metadata": {
        "id": "a799a27d-2f06-4794-846f-343377d62321"
      },
      "outputs": [],
      "source": [
        "landcover_list = [\n",
        "    {'mask': grasses, 'file_name': 'grasses_landcover'},\n",
        "    {'mask': low_density, 'file_name': 'low_density_landcover'},\n",
        "    {'mask': wetlands, 'file_name': 'wetlands_landcover'},\n",
        "    {'mask': open_water, 'file_name': 'open_water_landcover'}\n",
        "]\n",
        "\n",
        "for landcover in landcover_list:\n",
        "    summarize_landcover_pixels(landcover['mask'], landcover['file_name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f67d404-a5ff-4ab3-98d0-63dbc581fd4a",
      "metadata": {
        "id": "2f67d404-a5ff-4ab3-98d0-63dbc581fd4a"
      },
      "source": [
        "## 4. Tobacco Retailer Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c68d06c-0381-4344-800f-d2f269fdbcb6",
      "metadata": {
        "id": "5c68d06c-0381-4344-800f-d2f269fdbcb6"
      },
      "outputs": [],
      "source": [
        "all_retailers = pd.read_csv('PATH')\n",
        "pa_retailers = all_retailers[all_retailers['state'] == 'PA']\n",
        "pa_retailers = pa_retailers[[\"county\", \"license_type\", \"lat\", \"lon\"]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pa_retailers.to_csv('PATH', index=False)"
      ],
      "metadata": {
        "id": "l4Zj0VeTUTLT"
      },
      "id": "l4Zj0VeTUTLT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d7639974-6401-4288-b008-758100482e94",
      "metadata": {
        "id": "d7639974-6401-4288-b008-758100482e94"
      },
      "source": [
        "## 5. CDC Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9ea25b4-4bac-4865-b586-9b35d5da548a",
      "metadata": {
        "id": "e9ea25b4-4bac-4865-b586-9b35d5da548a"
      },
      "outputs": [],
      "source": [
        "cdc_data = pd.read_csv(\"PATH\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6b409f-3d3f-491a-bbf2-ed6e173e3438",
      "metadata": {
        "id": "5f6b409f-3d3f-491a-bbf2-ed6e173e3438"
      },
      "outputs": [],
      "source": [
        "# process CRD data\n",
        "PA_Asthma = cdc_data[(cdc_data['Measure'] == \"Current asthma among adults\") & (cdc_data['StateAbbr'] == \"PA\")]\n",
        "PA_COP = cdc_data[(cdc_data['Measure'] == \"Chronic obstructive pulmonary disease among adults\") & (cdc_data['StateAbbr'] == \"PA\")]\n",
        "PA_Chronic = PA_Asthma.merge(\n",
        "    PA_COP[['LocationName', 'Data_Value']],\n",
        "    on=\"LocationName\",\n",
        "    how=\"left\"\n",
        ").rename(columns={\"Data_Value_x\": \"Asthma\", \"Data_Value_y\": \"COP\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9b45af-fe0a-439e-bc00-0f279a136528",
      "metadata": {
        "id": "ef9b45af-fe0a-439e-bc00-0f279a136528"
      },
      "outputs": [],
      "source": [
        "PA_Chronic.to_csv('PATH', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d21670ca-bf38-431c-a5e7-60248c8774d3",
      "metadata": {
        "id": "d21670ca-bf38-431c-a5e7-60248c8774d3"
      },
      "outputs": [],
      "source": [
        "# process HRB data\n",
        "PA_Smoking = cdc_data[(cdc_data['Measure'] == \"Current cigarette smoking among adults\") & (cdc_data['StateAbbr'] == \"PA\")]\n",
        "PA_Drinking = cdc_data[(cdc_data['Measure'] == \"Binge drinking among adults\") & (cdc_data['StateAbbr'] == \"PA\")]\n",
        "PA_Physical_Activity = cdc_data[(cdc_data['Measure'] == \"No leisure-time physical activity among adults\") & (cdc_data['StateAbbr'] == \"PA\")]\n",
        "PA_Short_Sleep = cdc_data[(cdc_data['Measure'] == \"Short sleep duration among adults\") & (cdc_data['StateAbbr'] == \"PA\")]\n",
        "\n",
        "PA_HRB = PA_Smoking.merge(\n",
        "    PA_Drinking[['LocationName', 'Data_Value']], on='LocationName', how='left'\n",
        ").rename(columns={\"Data_Value_x\": \"Smoking\", \"Data_Value_y\": \"Drinking\"})\n",
        "\n",
        "PA_HRB = PA_HRB.merge(\n",
        "    PA_Physical_Activity[['LocationName', 'Data_Value']], on='LocationName', how='left'\n",
        ").rename(columns={'Data_Value': 'Physical_Activity'})\n",
        "\n",
        "PA_HRB = PA_HRB.merge(\n",
        "    PA_Short_Sleep[['LocationName', 'Data_Value']], on='LocationName', how='left'\n",
        ").rename(columns={'Data_Value': 'Short_Sleep'})\n",
        "PA_HRB[['LocationName', 'Smoking', 'Drinking', 'Physical_Activity', 'Short_Sleep']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "595366ef-86ec-4b29-b7ab-b76cc51f5251",
      "metadata": {
        "id": "595366ef-86ec-4b29-b7ab-b76cc51f5251"
      },
      "outputs": [],
      "source": [
        "PA_HRB.to_csv('PATH', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Census Data"
      ],
      "metadata": {
        "id": "e0rHGhrUUIHx"
      },
      "id": "e0rHGhrUUIHx"
    },
    {
      "cell_type": "code",
      "source": [
        "acs = cenpy.remote.APIConnection(\"ACSDT5Y2022\")"
      ],
      "metadata": {
        "id": "hrzpZGcVUHCS"
      },
      "id": "hrzpZGcVUHCS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "census_var = [\"NAME\",\n",
        "              \"B02001_001E\", # total\n",
        "              \"B02001_002E\", # white\n",
        "              \"B02001_003E\", # black\n",
        "              \"B02001_004E\", # native american\n",
        "              \"B02001_005E\", # asian\n",
        "              \"B03002_012E\", # hispanic\n",
        "              'B01001_020E', # male 65-66\n",
        "              'B01001_021E', # male 67-69\n",
        "              'B01001_022E', # male 70-74\n",
        "              'B01001_023E', # male 75-79\n",
        "              'B01001_024E', # male 80-84\n",
        "              'B01001_025E', # male over 85\n",
        "              'B01001_044E', # female 65-66\n",
        "              'B01001_045E', # female 67-69\n",
        "              'B01001_046E', # female 70-74\n",
        "              'B01001_047E', # female 75-79\n",
        "              'B01001_048E', # female 80-84\n",
        "              'B01001_049E', # female over 85\n",
        "              'B18101_007E', # Male 5 to 17 years With a disability\n",
        "              'B18101_010E', # Male 18 to 34 years With a disability\n",
        "              'B18101_013E', # Male 35 to 64 years With a disability\n",
        "              'B18101_016E', # Male 65 to 74 years With a disability\n",
        "              'B18101_019E', # Male over 75 years With a disability\n",
        "              'B18101_026E', # Female 5 to 17 years With a disability\n",
        "              'B18101_029E', # Female 18 to 34 years With a disability\n",
        "              'B18101_032E', # Female 35 to 64 years With a disability\n",
        "              'B18101_035E', # Female 65 to 74 years With a disability\n",
        "              'B18101_038E'\n",
        "             ]"
      ],
      "metadata": {
        "id": "FEWce-BnUdAv"
      },
      "id": "FEWce-BnUdAv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pa_state_code = \"42\"\n",
        "census_data = acs.query(\n",
        "    cols=census_var,\n",
        "    geo_unit=\"tract\",\n",
        "    geo_filter={\"state\": pa_state_code}\n",
        ")\n",
        "for variable in census_var:\n",
        "    if variable != \"NAME\":\n",
        "        census_data[variable] = census_data[variable].astype(float)"
      ],
      "metadata": {
        "id": "K4y9DpcEUfV9"
      },
      "id": "K4y9DpcEUfV9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "census_data['minority'] = (\n",
        "    (census_data['B02001_001E'] - census_data['B02001_002E']) / census_data['B02001_001E']\n",
        ")\n",
        "census_data['aging'] = (\n",
        "    census_data[[\n",
        "        'B01001_020E', 'B01001_021E', 'B01001_022E', 'B01001_023E',\n",
        "        'B01001_024E', 'B01001_025E', 'B01001_044E', 'B01001_045E',\n",
        "        'B01001_046E', 'B01001_047E', 'B01001_048E', 'B01001_049E'\n",
        "    ]].sum(axis=1) / census_data['B02001_001E']\n",
        ")\n",
        "census_data['disability'] = (\n",
        "    census_data[[\n",
        "        'B18101_007E', 'B18101_010E', 'B18101_013E', 'B18101_016E',\n",
        "        'B18101_019E', 'B18101_026E', 'B18101_029E', 'B18101_032E',\n",
        "        'B18101_035E', 'B18101_038E'\n",
        "    ]].sum(axis=1) / census_data['B02001_001E']\n",
        ")"
      ],
      "metadata": {
        "id": "WCr_vswDUjHy"
      },
      "id": "WCr_vswDUjHy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "census_data = census_data[[\"NAME\", \"county\", \"tract\", \"minority\", \"aging\", \"disability\"]]\n",
        "tracts = pygris.tracts(state=pa_state_code, year=2022)\n",
        "pa_census_data = tracts.merge(census_data, left_on=[\"COUNTYFP\", \"TRACTCE\"], right_on=[\"county\", \"tract\"],)\n",
        "pa_census_data = pa_census_data[[\"GEOID\", \"minority\", \"aging\", \"disability\", \"geometry\"]]"
      ],
      "metadata": {
        "id": "TcKNv5vqUldi"
      },
      "id": "TcKNv5vqUldi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pa_census_data.to_csv('PATH', index=False)"
      ],
      "metadata": {
        "id": "ZwX1fZDWUye8"
      },
      "id": "ZwX1fZDWUye8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}